{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXJDag1cXFXK",
        "outputId": "c023308b-7a72-4d3f-99b9-8e9b7a268587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Cleaning:\n",
            "   GDP_Growth  Inflation  Interest_Rate  Unemployment_Rate  Market_Return  \\\n",
            "0    4.331587   4.133137       6.693578           8.141387            NaN   \n",
            "1    3.715279   5.202744       4.170217           5.974250       0.938229   \n",
            "2    1.454600   2.975247       6.288859           7.551565       6.225925   \n",
            "3    2.991616   4.160399       6.653176           6.221437       0.273995   \n",
            "4    3.621336   2.869525       3.547584           8.297059       6.644017   \n",
            "\n",
            "             FX_Rate  Oil_Price  Portfolio_Exposure  Market_Volatility  \\\n",
            "0  88.05300890437982  87.059600              101244          21.234437   \n",
            "1  81.43066564704242  87.229868               95413                NaN   \n",
            "2  81.44232015450133  97.584729               43803          19.173247   \n",
            "3  86.70203017130547  74.468907               -5000          18.703803   \n",
            "4  86.73515605712606  73.939709               67906          21.412377   \n",
            "\n",
            "  Stress_Level  \n",
            "0          NaN  \n",
            "1            1  \n",
            "2            ?  \n",
            "3            ?  \n",
            "4          NaN  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   GDP_Growth          199 non-null    float64\n",
            " 1   Inflation           199 non-null    float64\n",
            " 2   Interest_Rate       199 non-null    float64\n",
            " 3   Unemployment_Rate   200 non-null    float64\n",
            " 4   Market_Return       199 non-null    float64\n",
            " 5   FX_Rate             200 non-null    object \n",
            " 6   Oil_Price           199 non-null    float64\n",
            " 7   Portfolio_Exposure  200 non-null    int64  \n",
            " 8   Market_Volatility   199 non-null    float64\n",
            " 9   Stress_Level        150 non-null    object \n",
            "dtypes: float64(7), int64(1), object(2)\n",
            "memory usage: 15.8+ KB\n",
            "None\n",
            "\n",
            "After Cleaning:\n",
            "   GDP_Growth  Inflation  Interest_Rate  Unemployment_Rate  Market_Return  \\\n",
            "0    4.331587   4.133137       6.693578           8.141387      -0.612166   \n",
            "1    3.715279   5.202744       4.170217           5.974250       0.938229   \n",
            "2    1.454600   2.975247       6.288859           7.551565       6.225925   \n",
            "3    2.991616   4.160399       6.653176           6.221437       0.273995   \n",
            "4    3.621336   2.869525       3.547584           8.297059       6.644017   \n",
            "\n",
            "     FX_Rate  Oil_Price  Portfolio_Exposure  Market_Volatility  Stress_Level  \n",
            "0  88.053009  87.059600        101244.00000          21.234437             2  \n",
            "1  81.430666  87.229868         95413.00000          20.230485             1  \n",
            "2  81.442320  97.584729         43803.00000          19.173247             2  \n",
            "3  86.702030  74.468907         67117.78392          18.703803             2  \n",
            "4  86.735156  73.939709         67906.00000          21.412377             2  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   GDP_Growth          200 non-null    float64\n",
            " 1   Inflation           200 non-null    float64\n",
            " 2   Interest_Rate       200 non-null    float64\n",
            " 3   Unemployment_Rate   200 non-null    float64\n",
            " 4   Market_Return       200 non-null    float64\n",
            " 5   FX_Rate             200 non-null    float64\n",
            " 6   Oil_Price           200 non-null    float64\n",
            " 7   Portfolio_Exposure  200 non-null    float64\n",
            " 8   Market_Volatility   200 non-null    float64\n",
            " 9   Stress_Level        200 non-null    int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 15.8 KB\n",
            "None\n",
            "\n",
            "Cleaned dataset saved as cleaned_financial_stress_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2083269821.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-2083269821.py:56: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Stress_Level\"].fillna(df[\"Stress_Level\"].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---------------- LOAD DATA -----------------\n",
        "df = pd.read_csv(\"/unclean_financial_stress_data.csv\")\n",
        "\n",
        "print(\"Before Cleaning:\")\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# --------------- STEP 1: REPLACE INVALID ENTRIES -----------------\n",
        "\n",
        "# Replace '?' with NaN\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# Convert FX_Rate to numeric\n",
        "df[\"FX_Rate\"] = pd.to_numeric(df[\"FX_Rate\"], errors=\"coerce\")\n",
        "\n",
        "# Convert Stress_Level to numeric\n",
        "df[\"Stress_Level\"] = pd.to_numeric(df[\"Stress_Level\"], errors=\"coerce\")\n",
        "\n",
        "# --------------- STEP 2: HANDLE NEGATIVE VALUES -----------------\n",
        "\n",
        "# Negative unemployment is invalid\n",
        "df.loc[df[\"Unemployment_Rate\"] < 0, \"Unemployment_Rate\"] = np.nan\n",
        "\n",
        "# Negative portfolio exposure is invalid\n",
        "df.loc[df[\"Portfolio_Exposure\"] < 0, \"Portfolio_Exposure\"] = np.nan\n",
        "\n",
        "# --------------- STEP 3: HANDLE OUTLIERS -----------------\n",
        "\n",
        "# Define outlier removal using IQR\n",
        "def remove_outliers(col):\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    df[col] = np.where((df[col] < lower) | (df[col] > upper), np.nan, df[col])\n",
        "\n",
        "numeric_cols = [\n",
        "    \"GDP_Growth\",\"Inflation\",\"Interest_Rate\",\"Unemployment_Rate\",\n",
        "    \"Market_Return\",\"FX_Rate\",\"Oil_Price\",\"Portfolio_Exposure\",\"Market_Volatility\"\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    remove_outliers(col)\n",
        "\n",
        "# --------------- STEP 4: HANDLE MISSING VALUES -----------------\n",
        "\n",
        "# Fill numeric missing values with column mean\n",
        "for col in numeric_cols:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)\n",
        "\n",
        "# Fill missing stress levels with mode\n",
        "df[\"Stress_Level\"].fillna(df[\"Stress_Level\"].mode()[0], inplace=True)\n",
        "\n",
        "# --------------- STEP 5: FINAL CLEANUP -----------------\n",
        "\n",
        "# Ensure correct data types\n",
        "df = df.astype({\n",
        "    \"GDP_Growth\": float,\n",
        "    \"Inflation\": float,\n",
        "    \"Interest_Rate\": float,\n",
        "    \"Unemployment_Rate\": float,\n",
        "    \"Market_Return\": float,\n",
        "    \"FX_Rate\": float,\n",
        "    \"Oil_Price\": float,\n",
        "    \"Portfolio_Exposure\": float,\n",
        "    \"Market_Volatility\": float,\n",
        "    \"Stress_Level\": int\n",
        "})\n",
        "\n",
        "print(\"\\nAfter Cleaning:\")\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# --------------- STEP 6: SAVE CLEANED DATASET -----------------\n",
        "df.to_csv(\"cleaned_financial_stress_data.csv\", index=False)\n",
        "print(\"\\nCleaned dataset saved as cleaned_financial_stress_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"/cleaned_financial_stress_data.csv\")\n",
        "\n",
        "X = df.drop(\"Stress_Level\", axis=1)\n",
        "y = df[\"Stress_Level\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXqFChVXXQHl",
        "outputId": "468c5cd3-d83f-4bf0-f9be-4e159a119216"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sk9fchZMXllv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"/cleaned_financial_stress_data.csv\")\n",
        "\n",
        "X = df.drop(\"Stress_Level\", axis=1)\n",
        "y = df[\"Stress_Level\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJXFiMA8XpDq",
        "outputId": "593baba5-e0e5-409a-8b8d-0323880623fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"/cleaned_financial_stress_data.csv\")\n",
        "\n",
        "X = df.drop(\"Stress_Level\", axis=1)\n",
        "y = df[\"Stress_Level\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = XGBClassifier(eval_metric='mlogloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"XGBoost Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsSqhXKxXvUE",
        "outputId": "f88054b4-aaa3-4e80-fd23-0f564a560207"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"/content/cleaned_financial_stress_data.csv\")\n",
        "\n",
        "X = df.drop(\"Stress_Level\", axis=1)\n",
        "y = df[\"Stress_Level\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"SVM Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuQM6IrlX4mN",
        "outputId": "5a6d5277-4eb3-4a43-e40a-71adce96abe1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oBEczyAUXu6o"
      }
    }
  ]
}